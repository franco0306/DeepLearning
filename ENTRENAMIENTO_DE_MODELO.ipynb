{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Re_LzjcbkFu",
        "outputId": "635e9cb9-306e-4249-f80c-10fbd3bf1067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Rutas corregidas\n",
        "at = Path(\"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/data_atento\")\n",
        "de = Path(\"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/data_desatento\")\n",
        "\n",
        "def contar(p):\n",
        "    exts = [\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.JPG\",\"*.JPEG\",\"*.PNG\",\"*.mp4\",\"*.avi\",\"*.MOV\"]\n",
        "    n = 0\n",
        "    for e in exts:\n",
        "        n += len(list(p.glob(e)))\n",
        "    return n\n",
        "\n",
        "print(\"ATENTO:\", contar(at))\n",
        "print(\"DESATENTO:\", contar(de))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMRINmlIbvyd",
        "outputId": "a20a0431-283e-4e66-f2d2-e1a6ef6654c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ATENTO: 7\n",
            "DESATENTO: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, uuid\n",
        "from pathlib import Path\n",
        "\n",
        "# Entradas: TUS videos\n",
        "INPUT_AT  = Path(\"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/data_atento\")\n",
        "INPUT_DE  = Path(\"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/data_desatento\")\n",
        "\n",
        "# Salidas: frames (se crean si no existen)\n",
        "OUT_AT    = Path(\"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/frames_atento\")\n",
        "OUT_DE    = Path(\"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/frames_desatento\")\n",
        "for d in [OUT_AT, OUT_DE]: d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Detector de rostro (Haarcascade simple)\n",
        "face = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "def extraer(video_path: Path, out_dir: Path, every_sec: float = 0.5) -> int:\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        print(f\"[X] No abre: {video_path}\")\n",
        "        return 0\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "    step = max(1, int(round(fps * every_sec)))\n",
        "\n",
        "    saved, i = 0, 0\n",
        "    ok, frame = cap.read()\n",
        "    while ok:\n",
        "        if i % step == 0:\n",
        "            img = frame\n",
        "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            faces = face.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n",
        "            if len(faces):\n",
        "                x,y,w,h = max(faces, key=lambda b: b[2]*b[3])\n",
        "                pad = int(0.15 * max(w, h))\n",
        "                x0,y0 = max(0, x - pad), max(0, y - pad)\n",
        "                x1,y1 = min(frame.shape[1], x + w + pad), min(frame.shape[0], y + h + pad)\n",
        "                img = frame[y0:y1, x0:x1]\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            cv2.imwrite(str(out_dir / f\"{video_path.stem}_{uuid.uuid4().hex[:8]}.jpg\"), img)\n",
        "            saved += 1\n",
        "        i += 1\n",
        "        ok, frame = cap.read()\n",
        "    cap.release()\n",
        "    return saved\n",
        "\n",
        "# Procesar todos los videos (varias extensiones)\n",
        "exts = [\"*.mp4\",\"*.MP4\",\"*.mov\",\"*.MOV\",\"*.avi\",\"*.AVI\"]\n",
        "\n",
        "total_at = total_de = 0\n",
        "for ext in exts:\n",
        "    for v in INPUT_AT.glob(ext):\n",
        "        total_at += extraer(v, OUT_AT, every_sec=0.5)\n",
        "    for v in INPUT_DE.glob(ext):\n",
        "        total_de += extraer(v, OUT_DE, every_sec=0.5)\n",
        "\n",
        "print(f\"Frames ATENTO: {total_at} | Frames DESATENTO: {total_de}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZl87z0db1pn",
        "outputId": "2f5a4a32-dbc9-4aac-e9cb-298b583360ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames ATENTO: 1095 | Frames DESATENTO: 940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, shutil\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "FR_AT = Path(\"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/frames_atento\")\n",
        "FR_DE = Path(\"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/frames_desatento\")\n",
        "\n",
        "BASE = Path(\"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/data\")  # dataset final\n",
        "for s in [\"train\",\"val\",\"test\"]:\n",
        "    for c in [\"atento\",\"desatento\"]:\n",
        "        (BASE/s/c).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def listar(root: Path, label: str):\n",
        "    exts = [\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.JPG\",\"*.JPEG\",\"*.PNG\"]\n",
        "    rows=[]\n",
        "    for e in exts:\n",
        "        rows += [{\"path\": str(p), \"label\": label} for p in root.glob(e)]\n",
        "    return rows\n",
        "\n",
        "df = pd.DataFrame(listar(FR_AT, \"atento\") + listar(FR_DE, \"desatento\"))\n",
        "assert not df.empty, \"No hay frames en frames_atento / frames_desatento.\"\n",
        "\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "# 70/15/15 estratificado\n",
        "train_df, temp = train_test_split(df, test_size=0.30, stratify=df[\"label\"], random_state=42)\n",
        "val_df, test_df = train_test_split(temp, test_size=0.50, stratify=temp[\"label\"], random_state=42)\n",
        "\n",
        "def mover(split_df, split_name):\n",
        "    for _, r in split_df.iterrows():\n",
        "        src = Path(r.path)\n",
        "        dst = BASE/split_name/r.label/src.name\n",
        "        if not dst.exists():\n",
        "            shutil.move(str(src), str(dst))\n",
        "\n",
        "mover(train_df, \"train\"); mover(val_df, \"val\"); mover(test_df, \"test\")\n",
        "\n",
        "print(\"✅ Split completo\")\n",
        "print(\"Train:\", sum(1 for _ in (BASE/'train').rglob('*.jpg')))\n",
        "print(\"Val:  \", sum(1 for _ in (BASE/'val').rglob('*.jpg')))\n",
        "print(\"Test: \", sum(1 for _ in (BASE/'test').rglob('*.jpg')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "XWq2yw1ki1_T",
        "outputId": "b05e0675-044f-480a-9c3d-1cb122ca735f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "No hay frames en frames_atento / frames_desatento.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3447234368.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFR_AT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"atento\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFR_DE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"desatento\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No hay frames en frames_atento / frames_desatento.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: No hay frames en frames_atento / frames_desatento."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Celda 5 — Entrenar MobileNetV2 (baseline + fine-tuning) =====\n",
        "import os, math\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "\n",
        "# --- Rutas del dataset final (de la Celda 4) ---\n",
        "BASE = Path(\"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/data\")\n",
        "IMG = 224\n",
        "BATCH = 32\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "# --- Data loaders ---\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    BASE/\"train\", image_size=(IMG, IMG), batch_size=BATCH, label_mode=\"binary\")\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    BASE/\"val\", image_size=(IMG, IMG), batch_size=BATCH, label_mode=\"binary\")\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    BASE/\"test\", image_size=(IMG, IMG), batch_size=BATCH, label_mode=\"binary\", shuffle=False)\n",
        "\n",
        "# Opcional: inspección rápida de balance de clases\n",
        "def count_by_label(ds):\n",
        "    c0 = c1 = 0\n",
        "    for x, y in ds.unbatch():\n",
        "        if int(y.numpy()[0]) == 0: c0 += 1\n",
        "        else: c1 += 1\n",
        "    return c0, c1\n",
        "\n",
        "c0_tr, c1_tr = count_by_label(train_ds)\n",
        "print(f\"[Train] desatento: {c0_tr} | atento: {c1_tr}\")\n",
        "\n",
        "# --- Augmentations + preprocesamiento ---\n",
        "data_aug = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.05),\n",
        "    tf.keras.layers.RandomZoom(0.10),\n",
        "    tf.keras.layers.RandomContrast(0.10),\n",
        "    tf.keras.layers.RandomBrightness(0.10),\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "def prep(ds, train=True):\n",
        "    ds = ds.shuffle(1000) if train else ds\n",
        "    ds = ds.map(lambda x,y: (tf.keras.applications.mobilenet_v2.preprocess_input(x), y),\n",
        "                num_parallel_calls=AUTO)\n",
        "    return ds.cache().prefetch(AUTO)\n",
        "\n",
        "# Notas:\n",
        "# - data_aug se aplica dentro del modelo (para que ocurra en GPU y en train únicamente)\n",
        "train_ds_prep = prep(train_ds, train=True)\n",
        "val_ds_prep   = prep(val_ds,   train=False)\n",
        "test_ds_prep  = prep(test_ds,  train=False)\n",
        "\n",
        "# --- Modelo MobileNetV2 ---\n",
        "base = tf.keras.applications.MobileNetV2(\n",
        "    include_top=False, weights=\"imagenet\", input_shape=(IMG, IMG, 3))\n",
        "base.trainable = False  # baseline: congelada\n",
        "\n",
        "inputs = tf.keras.Input((IMG, IMG, 3))\n",
        "x = data_aug(inputs)  # augment SOLO en entrenamiento\n",
        "x = base(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.25)(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"AUC\")])\n",
        "\n",
        "# --- Callbacks ---\n",
        "ckpt_path = \"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/modelos/atencion_mnv2_baseline.keras\"\n",
        "os.makedirs(os.path.dirname(ckpt_path), exist_ok=True)\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(ckpt_path, monitor=\"val_accuracy\",\n",
        "                                       save_best_only=True, mode=\"max\", verbose=1),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3,\n",
        "                                     restore_best_weights=True, mode=\"max\", verbose=1)\n",
        "]\n",
        "\n",
        "# --- Entrenamiento baseline ---\n",
        "EPOCHS_BASE = 20\n",
        "hist_base = model.fit(train_ds_prep, validation_data=val_ds_prep,\n",
        "                      epochs=EPOCHS_BASE, callbacks=callbacks)\n",
        "\n",
        "# --- Fine-tuning: descongelar últimas capas del backbone ---\n",
        "base.trainable = True\n",
        "# Deja congeladas las primeras capas, libera ~las últimas 40 (ajusta si quieres)\n",
        "for layer in base.layers[:-40]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Re-compilar con LR más pequeño para no destruir pesos preentrenados\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"AUC\")])\n",
        "\n",
        "ckpt_ft_path = \"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/modelos/atencion_mnv2_finetune.keras\"\n",
        "callbacks_ft = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(ckpt_ft_path, monitor=\"val_accuracy\",\n",
        "                                       save_best_only=True, mode=\"max\", verbose=1),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3,\n",
        "                                     restore_best_weights=True, mode=\"max\", verbose=1)\n",
        "]\n",
        "\n",
        "EPOCHS_FT = 15\n",
        "hist_ft = model.fit(train_ds_prep, validation_data=val_ds_prep,\n",
        "                    epochs=EPOCHS_FT, callbacks=callbacks_ft)\n",
        "\n",
        "# --- Evaluación rápida en test ---\n",
        "print(\"\\nEvaluación en TEST:\")\n",
        "model.evaluate(test_ds_prep, verbose=1)\n",
        "\n",
        "# --- Guardar modelo final ---\n",
        "final_path = \"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/modelos/atencion_mnv2_final.keras\"\n",
        "model.save(final_path)\n",
        "print(f\"Modelo guardado en: {final_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyfDZqKVkf0J",
        "outputId": "5bfa8f4a-4ec7-4e7a-875f-46976c83ed69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4912 files belonging to 2 classes.\n",
            "Found 931 files belonging to 2 classes.\n",
            "Found 931 files belonging to 2 classes.\n",
            "[Train] desatento: 2553 | atento: 2359\n",
            "Epoch 1/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - AUC: 0.5231 - accuracy: 0.5224 - loss: 0.7270\n",
            "Epoch 1: val_accuracy improved from -inf to 0.62728, saving model to drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/modelos/atencion_mnv2_baseline.keras\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 113ms/step - AUC: 0.5233 - accuracy: 0.5225 - loss: 0.7269 - val_AUC: 0.6764 - val_accuracy: 0.6273 - val_loss: 0.6621\n",
            "Epoch 2/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - AUC: 0.6045 - accuracy: 0.5721 - loss: 0.6789\n",
            "Epoch 2: val_accuracy did not improve from 0.62728\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - AUC: 0.6046 - accuracy: 0.5722 - loss: 0.6788 - val_AUC: 0.7026 - val_accuracy: 0.5016 - val_loss: 0.8773\n",
            "Epoch 3/20\n",
            "\u001b[1m153/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - AUC: 0.6379 - accuracy: 0.5959 - loss: 0.6570\n",
            "Epoch 3: val_accuracy did not improve from 0.62728\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - AUC: 0.6381 - accuracy: 0.5960 - loss: 0.6569 - val_AUC: 0.7014 - val_accuracy: 0.5446 - val_loss: 0.7946\n",
            "Epoch 4/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - AUC: 0.6658 - accuracy: 0.6103 - loss: 0.6351\n",
            "Epoch 4: val_accuracy did not improve from 0.62728\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - AUC: 0.6658 - accuracy: 0.6103 - loss: 0.6350 - val_AUC: 0.7107 - val_accuracy: 0.5231 - val_loss: 0.9806\n",
            "Epoch 4: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Epoch 1/15\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - AUC: 0.6140 - accuracy: 0.5750 - loss: 0.7096\n",
            "Epoch 1: val_accuracy improved from -inf to 0.54672, saving model to drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/modelos/atencion_mnv2_finetune.keras\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 182ms/step - AUC: 0.6143 - accuracy: 0.5752 - loss: 0.7092 - val_AUC: 0.6757 - val_accuracy: 0.5467 - val_loss: 0.6414\n",
            "Epoch 2/15\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - AUC: 0.7434 - accuracy: 0.6559 - loss: 0.5752\n",
            "Epoch 2: val_accuracy improved from 0.54672 to 0.66917, saving model to drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/modelos/atencion_mnv2_finetune.keras\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 116ms/step - AUC: 0.7435 - accuracy: 0.6559 - loss: 0.5751 - val_AUC: 0.6979 - val_accuracy: 0.6692 - val_loss: 0.6404\n",
            "Epoch 3/15\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - AUC: 0.7733 - accuracy: 0.6801 - loss: 0.5445\n",
            "Epoch 3: val_accuracy improved from 0.66917 to 0.69495, saving model to drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/modelos/atencion_mnv2_finetune.keras\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 155ms/step - AUC: 0.7733 - accuracy: 0.6800 - loss: 0.5444 - val_AUC: 0.7219 - val_accuracy: 0.6950 - val_loss: 0.6297\n",
            "Epoch 4/15\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - AUC: 0.7804 - accuracy: 0.6829 - loss: 0.5292\n",
            "Epoch 4: val_accuracy improved from 0.69495 to 0.70569, saving model to drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/modelos/atencion_mnv2_finetune.keras\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 165ms/step - AUC: 0.7805 - accuracy: 0.6829 - loss: 0.5291 - val_AUC: 0.7373 - val_accuracy: 0.7057 - val_loss: 0.6293\n",
            "Epoch 5/15\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - AUC: 0.8148 - accuracy: 0.7092 - loss: 0.4846\n",
            "Epoch 5: val_accuracy did not improve from 0.70569\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - AUC: 0.8148 - accuracy: 0.7092 - loss: 0.4846 - val_AUC: 0.7719 - val_accuracy: 0.6928 - val_loss: 0.6469\n",
            "Epoch 6/15\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - AUC: 0.8152 - accuracy: 0.7096 - loss: 0.4870\n",
            "Epoch 6: val_accuracy did not improve from 0.70569\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 82ms/step - AUC: 0.8152 - accuracy: 0.7096 - loss: 0.4869 - val_AUC: 0.8064 - val_accuracy: 0.6950 - val_loss: 0.6168\n",
            "Epoch 7/15\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - AUC: 0.8128 - accuracy: 0.7074 - loss: 0.4713\n",
            "Epoch 7: val_accuracy did not improve from 0.70569\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - AUC: 0.8128 - accuracy: 0.7075 - loss: 0.4712 - val_AUC: 0.8430 - val_accuracy: 0.6939 - val_loss: 0.5988\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\n",
            "Evaluación en TEST:\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - AUC: 0.3276 - accuracy: 0.8685 - loss: 0.4710\n",
            "Modelo guardado en: drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/modelos/atencion_mnv2_final.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UMBRAL = 0.25  # Ajusta el umbral un poco más bajo\n"
      ],
      "metadata": {
        "id": "4MgR36i8RnhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = {0:1.0, 1:1.2}  # Aumentar un poco más el peso de \"desatento\"\n",
        "model.fit(train_ds_prep, validation_data=val_ds_prep, epochs=EPOCHS_BASE, class_weight=class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5FCW-qwRoYe",
        "outputId": "005edb60-3349-47a2-899d-3aeb188a7eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 90ms/step - accuracy: 0.7219 - loss: 0.4495 - val_accuracy: 0.7991 - val_loss: 0.4179\n",
            "Epoch 2/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7508 - loss: 0.4141 - val_accuracy: 0.7938 - val_loss: 0.4215\n",
            "Epoch 3/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7364 - loss: 0.4175 - val_accuracy: 0.7927 - val_loss: 0.4348\n",
            "Epoch 4/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7348 - loss: 0.4256 - val_accuracy: 0.7830 - val_loss: 0.4408\n",
            "Epoch 5/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7303 - loss: 0.4306 - val_accuracy: 0.8464 - val_loss: 0.3849\n",
            "Epoch 6/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7606 - loss: 0.3993 - val_accuracy: 0.8292 - val_loss: 0.3835\n",
            "Epoch 7/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 78ms/step - accuracy: 0.7413 - loss: 0.4156 - val_accuracy: 0.8088 - val_loss: 0.4069\n",
            "Epoch 8/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7517 - loss: 0.3934 - val_accuracy: 0.8507 - val_loss: 0.3748\n",
            "Epoch 9/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7455 - loss: 0.4130 - val_accuracy: 0.7841 - val_loss: 0.4401\n",
            "Epoch 10/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7474 - loss: 0.4102 - val_accuracy: 0.7927 - val_loss: 0.4534\n",
            "Epoch 11/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7446 - loss: 0.4240 - val_accuracy: 0.8067 - val_loss: 0.4320\n",
            "Epoch 12/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7497 - loss: 0.3980 - val_accuracy: 0.7830 - val_loss: 0.4981\n",
            "Epoch 13/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7452 - loss: 0.4022 - val_accuracy: 0.7336 - val_loss: 0.5703\n",
            "Epoch 14/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7488 - loss: 0.4139 - val_accuracy: 0.7658 - val_loss: 0.5098\n",
            "Epoch 15/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7448 - loss: 0.4013 - val_accuracy: 0.7691 - val_loss: 0.4913\n",
            "Epoch 16/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7536 - loss: 0.4034 - val_accuracy: 0.7712 - val_loss: 0.5106\n",
            "Epoch 17/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.7238 - loss: 0.4154 - val_accuracy: 0.7959 - val_loss: 0.4732\n",
            "Epoch 18/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - accuracy: 0.7477 - loss: 0.3929 - val_accuracy: 0.7701 - val_loss: 0.5627\n",
            "Epoch 19/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - accuracy: 0.7499 - loss: 0.3956 - val_accuracy: 0.7755 - val_loss: 0.5247\n",
            "Epoch 20/20\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - accuracy: 0.7332 - loss: 0.4162 - val_accuracy: 0.7905 - val_loss: 0.5071\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d6605efbda0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base.trainable = True\n",
        "for layer in base.layers[:-40]:  # Puedes experimentar con un número diferente de capas\n",
        "    layer.trainable = False\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "uzFZzmBQR5CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ver clases y consistencia en cada split ===\n",
        "print(\"train class_names:\", train_ds.class_names)\n",
        "print(\"val   class_names:\", val_ds.class_names)\n",
        "print(\"test  class_names:\", test_ds.class_names)\n",
        "# Nota: image_dataset_from_directory asigna 0/1 en orden alfabético.\n",
        "# Con carpetas ['atento','desatento'] -> 0='atento', 1='desatento'\n",
        "\n",
        "# === Obtener probabilidades del modelo en VAL para elegir umbral óptimo ===\n",
        "import numpy as np, tensorflow as tf\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "# Convierte dataset a arrays (VAL)\n",
        "y_val = []\n",
        "y_val_prob = []\n",
        "for xb, yb in val_ds_prep:\n",
        "    y_val.append(yb.numpy().ravel())\n",
        "    y_val_prob.append(model.predict(xb, verbose=0).ravel())\n",
        "y_val = np.concatenate(y_val)\n",
        "y_val_prob = np.concatenate(y_val_prob)\n",
        "\n",
        "# AUC en val\n",
        "val_auc = roc_auc_score(y_val, y_val_prob)\n",
        "print(f\"VAL AUC: {val_auc:.3f}\")\n",
        "\n",
        "# Umbral óptimo por criterio de Youden J (tpr - fpr máximo)\n",
        "fpr, tpr, thr = roc_curve(y_val, y_val_prob)\n",
        "youden = tpr - fpr\n",
        "best_idx = np.argmax(youden)\n",
        "best_thr = thr[best_idx]\n",
        "print(f\"Umbral óptimo (Youden): {best_thr:.3f}\")\n",
        "\n",
        "# === Evaluar en TEST con ese umbral ===\n",
        "y_test = []\n",
        "y_test_prob = []\n",
        "for xb, yb in test_ds_prep:\n",
        "    y_test.append(yb.numpy().ravel())\n",
        "    y_test_prob.append(model.predict(xb, verbose=0).ravel())\n",
        "y_test = np.concatenate(y_test)\n",
        "y_test_prob = np.concatenate(y_test_prob)\n",
        "\n",
        "test_auc = roc_auc_score(y_test, y_test_prob)\n",
        "print(f\"TEST AUC (sin invertir): {test_auc:.3f}\")\n",
        "\n",
        "# Si AUC < 0.5, probar invertir (posible inversión de mapeo)\n",
        "if test_auc < 0.5:\n",
        "    y_test_prob_inv = 1.0 - y_test_prob\n",
        "    test_auc_inv = roc_auc_score(y_test, y_test_prob_inv)\n",
        "    print(f\"TEST AUC invertido: {test_auc_inv:.3f}  (probable inversión de clases)\")\n",
        "    # Usar el invertido si es mejor\n",
        "    use_prob = y_test_prob_inv if test_auc_inv > test_auc else y_test_prob\n",
        "else:\n",
        "    use_prob = y_test_prob\n",
        "\n",
        "# Predicciones binarias con el mejor umbral de VAL\n",
        "y_pred = (use_prob >= best_thr).astype(int)\n",
        "\n",
        "# Reporte\n",
        "print(\"\\n== Clasificación (TEST) ==\")\n",
        "print(classification_report(y_test, y_pred, target_names=test_ds.class_names))\n",
        "\n",
        "print(\"Matriz de confusión [filas=verdadero, cols=pred]:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8CpPVL1lj0z",
        "outputId": "cfdb5bf0-cc37-4af5-e0b7-e9a5bc663f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train class_names: ['atento', 'desatento']\n",
            "val   class_names: ['atento', 'desatento']\n",
            "test  class_names: ['atento', 'desatento']\n",
            "VAL AUC: 0.912\n",
            "Umbral óptimo (Youden): 0.206\n",
            "TEST AUC (sin invertir): 0.935\n",
            "\n",
            "== Clasificación (TEST) ==\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      atento       0.87      0.91      0.89       480\n",
            "   desatento       0.90      0.85      0.87       451\n",
            "\n",
            "    accuracy                           0.88       931\n",
            "   macro avg       0.88      0.88      0.88       931\n",
            "weighted avg       0.88      0.88      0.88       931\n",
            "\n",
            "Matriz de confusión [filas=verdadero, cols=pred]:\n",
            "[[437  43]\n",
            " [ 67 384]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define la ruta para guardar el modelo\n",
        "final_path = \"drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/modelos/atencion_mnv2_final_mejorado.keras\"\n",
        "\n",
        "# Guarda el modelo\n",
        "model.save(final_path)\n",
        "\n",
        "print(f\"Modelo guardado en: {final_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tt1hI3eTGU0",
        "outputId": "93b3da1e-6235-43c1-8577-23b568b94e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado en: drive/MyDrive/UPAO/VIII/Deep Learning/Proyecto/modelos/atencion_mnv2_final_mejorado.keras\n"
          ]
        }
      ]
    }
  ]
}